{
 "metadata": {
  "name": "",
  "signature": "sha256:42372020ab74b2ed120452a05b510156183920a12566fcd87a3911dfc2c815e8"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "http://nbviewer.ipython.org/gist/rjweiss/7577004"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "from sklearn.preprocessing import LabelEncoder \n",
      "from sklearn import cross_validation\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import re\n",
      "import nltk\n",
      "from nltk.stem.porter import PorterStemmer\n",
      "from nltk.stem.snowball import SnowballStemmer\n",
      "from nltk.stem.wordnet import WordNetLemmatizer\n",
      "from bs4 import BeautifulSoup\n",
      "from nltk.corpus import stopwords\n",
      "\n",
      "class stemmerUtility(object):\n",
      "    \"\"\"Stemming functionality\"\"\"\n",
      "    @staticmethod\n",
      "    def stemPorter(review_text):\n",
      "        porter = PorterStemmer()\n",
      "        preprocessed_docs = []\n",
      "        for doc in review_text:\n",
      "            final_doc = []\n",
      "            for word in doc:\n",
      "                final_doc.append(porter.stem(word))\n",
      "                #final_doc.append(snowball.stem(word))\n",
      "                #final_doc.append(wordnet.lemmatize(word)) #note that lemmatize() can also takes part of speech as an argument!\n",
      "            preprocessed_docs.append(final_doc)\n",
      "        return preprocessed_docs\n",
      "\n",
      "\n",
      "class KaggleWord2VecUtility(object):\n",
      "    \"\"\"KaggleWord2VecUtility is a utility class for processing raw HTML text into segments for further learning\"\"\"\n",
      "\n",
      "    @staticmethod\n",
      "    def review_to_wordlist( review, remove_stopwords=False ):\n",
      "        # 1. Remove HTML\n",
      "        review_text = BeautifulSoup(review).get_text()\n",
      "        # 2. Remove non-letters\n",
      "        review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n",
      "        # 2.1 Remove single letters\n",
      "        review_text = re.sub('/(?<!\\S).(?!\\S)\\s*/', '', review_text);\n",
      "        # 3. Convert words to lower case and split them\n",
      "        words = review_text.lower().split()\n",
      "        newwords=[]\n",
      "        for word in words:\n",
      "            if len(word)>2:\n",
      "                newwords.append(word)\n",
      "        # 4. Optionally remove stop words (false by default)\n",
      "        if remove_stopwords:\n",
      "            stops = set(stopwords.words(\"english\"))\n",
      "            newwords = [w for w in newwords if not w in stops]\n",
      "        #\n",
      "        # 5. Return a list of words\n",
      "        return(newwords)\n",
      "\n",
      "    # Define a function to split a review into parsed sentences\n",
      "    @staticmethod\n",
      "    def review_to_sentences( review, tokenizer, remove_stopwords=False ):\n",
      "        # Function to split a review into parsed sentences. Returns a\n",
      "        # list of sentences, where each sentence is a list of words\n",
      "        #\n",
      "        # 1. Use the NLTK tokenizer to split the paragraph into sentences\n",
      "        raw_sentences = tokenizer.tokenize(review.decode('utf8').strip())\n",
      "        #\n",
      "        # 2. Loop over each sentence\n",
      "        sentences = []\n",
      "        for raw_sentence in raw_sentences:\n",
      "            # If a sentence is empty, skip it\n",
      "            if len(raw_sentence) > 0:\n",
      "                # Otherwise, call review_to_wordlist to get a list of words\n",
      "                sentences.append( KaggleWord2VecUtility.review_to_wordlist( raw_sentence, \\\n",
      "                  remove_stopwords ))\n",
      "        #\n",
      "        # Return the list of sentences (each sentence is a list of words,\n",
      "        # so this returns a list of lists\n",
      "        return sentences\n",
      "    \n",
      "train = pd.read_csv(\"/Users/taposh/workspace/kaggle/bow/labeledTrainData.tsv\", header=0,delimiter=\"\\t\", quoting=3)\n",
      "test = pd.read_csv(\"/Users/taposh/workspace/kaggle/bow/testData.tsv\", header=0, delimiter=\"\\t\",quoting=3)    \n",
      "\n",
      "#train = pd.read_csv(\"/Users/taposh/workspace/kaggle/bow/labeledTrainData.tsv\", header=0, \\\n",
      "#                    delimiter=\"\\t\", quoting=3)\n",
      "#test = pd.read_csv(\"/Users/taposh/workspace/kaggle/bow/testData.tsv\", header=0, delimiter=\"\\t\", \\\n",
      "                   #quoting=3 )\n",
      "y = train[\"sentiment\"]  \n",
      "print(\"Cleaning and parsing movie reviews...\\n\")      \n",
      "traindata = []\n",
      "for i in range( 0, len(train[\"review\"])):\n",
      "#for i in range(0,10):    \n",
      "    traindata.append(\" \".join(KaggleWord2VecUtility.review_to_wordlist(train[\"review\"][i], False)))\n",
      "testdata = []\n",
      "####\n",
      "for i in range(0,len(test[\"review\"])):\n",
      "    testdata.append(\" \".join(KaggleWord2VecUtility.review_to_wordlist(test[\"review\"][i], False)))\n",
      "    #print(testdata)\n",
      "print ('vectorizing... ',) \n",
      "tfv = TfidfVectorizer(min_df=2,  max_features=None, \n",
      "        strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n",
      "        ngram_range=(1, 2), use_idf=2,smooth_idf=1,sublinear_tf=1,\n",
      "        stop_words = 'english')\n",
      "X_all = traindata + testdata\n",
      "lentrain = len(traindata)\n",
      "\n",
      "\n",
      "print (\"fitting pipeline... \",)\n",
      "tfv.fit(X_all)\n",
      "X_all = tfv.transform(X_all)\n",
      "\n",
      "# RF transform 1st column to numbers\n",
      "#X_all[:,0] = LabelEncoder().fit_transform(X_all[:,0])\n",
      "\n",
      "\n",
      "#for Logit\n",
      "X = X_all[:lentrain]\n",
      "X_test = X_all[lentrain:]\n",
      "\n",
      "\n",
      "#model = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None\n",
      "model = LogisticRegression(penalty='l2', dual=True, tol=0.0001,C=14, fit_intercept=True, intercept_scaling=1,class_weight=None, random_state=None)\n",
      "\n",
      "#model = RandomForestRegressor(n_estimators=150, min_samples_split=1)\n",
      "#model.fit(X, y)\n",
      "#print X\n",
      "#print regressor.predict(X)\n",
      "\n",
      "print(\"25 Fold CV Score: \", np.mean(cross_validation.cross_val_score(model, X, y, cv=36, scoring='roc_auc')))\n",
      "\n",
      "print(\"Retrain on all training data, predicting test labels...\\n\")\n",
      "model.fit(X,y)\n",
      "result = model.predict_proba(X_test)[:,1]\n",
      "#result = model.predict(X_test)\n",
      "print(round(result))\n",
      "output = pd.DataFrame( data={\"id\":test[\"id\"], \"sentiment\":result} )\n",
      "\n",
      "import csv\n",
      "# Use pandas to write the comma-separated output file\n",
      "output.to_csv('/Users/taposh/workspace/kaggle/bow/Bag_of_Words_model_v17.csv',quoting=3, escapechar=\",\",index=False,encoding='utf-8')\n",
      "#output.to_csv(\"/Users/taposhdr/workspace/decision_science/kaggle/bow/data/Bag_of_Words_model-1.csv\", index=False, quoting=csv.QUOTE_NONE)\n",
      "print(\"Wrote results to Bag_of_Words_model.csv\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Cleaning and parsing movie reviews...\n",
        "\n",
        "vectorizing... "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "with all this stuff going down the moment with started listening his music watching the odd documentary here and there watched the wiz and watched moonwalker again maybe just want get certain insight into this guy who thought was really cool the eighties just maybe make mind whether guilty innocent moonwalker part biography part feature film which remember going see the cinema when was originally released some has subtle messages about feeling towards the press and also the obvious message drugs are bad kay visually impressive but course this all about michael jackson unless you remotely like anyway then you are going hate this and find boring some may call egotist for consenting the making this movie but and most his fans would say that made for the fans which true really nice him the actual feature film bit when finally starts only for minutes excluding the smooth criminal sequence and joe pesci convincing psychopathic all powerful drug lord why wants dead bad beyond because overheard his plans nah joe pesci character ranted that wanted people know who supplying drugs etc dunno maybe just hates music lots cool things this like turning into car and robot and the whole speed demon sequence also the director must have had the patience saint when came filming the kiddy bad sequence usually directors hate working with one kid let alone whole bunch them performing complex dance scene bottom line this movie for people who like one level another which think most people not then stay away does try and give off wholesome message and ironically bestest buddy this movie girl michael jackson truly one the most talented people ever grace this planet but guilty well with all the attention gave this subject hmmm well don know because people can different behind closed doors know this for fact either extremely nice but stupid guy one the most sickest liars hope not the latter"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "the classic war the worlds timothy hines very entertaining film that obviously goes great effort and lengths faithfully recreate wells classic book hines succeeds doing and those who watched his film with appreciated the fact that was not the standard predictable hollywood fare that comes out every year the spielberg version with tom cruise that had only the slightest resemblance the book obviously everyone looks for different things movie those who envision themselves amateur critics look only criticize everything they can others rate movie more important bases like being entertained which why most people never agree with the critics enjoyed the effort hines put into being faithful wells classic novel and found very entertaining this made easy overlook what the critics perceive its shortcomings\n",
        "the film starts with manager nicholas bell giving welcome investors robert carradine primal park secret project mutating primal animal using fossilized dna like jurassik park and some scientists resurrect one nature most fearsome predators the sabretooth tiger smilodon scientific ambition turns deadly however and when the high voltage fence opened the creature escape and begins savagely stalking its prey the human visitors tourists and scientific meanwhile some youngsters enter the restricted area the security center and are attacked pack large pre historical animals which are deadlier and bigger addition security agent stacy haiduk and her mate brian wimmer fight hardly against the carnivorous smilodons the sabretooths themselves course are the real star stars and they are astounding terrifyingly though not convincing the giant animals savagely are stalking its prey and the group run afoul and fight against one nature most fearsome predators furthermore third sabretooth more dangerous and slow stalks its victims the movie delivers the goods with lots blood and gore beheading hair raising chills full scares when the sabretooths appear with mediocre special effects the story provides exciting and stirring entertainment but results quite boring the giant animals are majority made computer generator and seem totally lousy middling performances though the players reacting appropriately becoming food actors give vigorously physical performances dodging the beasts running bound and leaps dangling over walls and packs ridiculous final deadly scene for small kids realistic gory and violent attack scenes other films about sabretooths smilodon are the following sabretooth james hickox with vanessa angel david keith and john rhys davies and the much better roland emmerich with with steven strait cliff curtis and camilla belle this motion picture filled with bloody moments badly directed george miller and with originality because takes too many elements from previous films miller australian director usually working for television tidal wave journey the center the earth and many others and occasionally for cinema the man from snowy river zeus and roxanne robinson crusoe rating below average bottom barrel\n",
        "must assumed that those who praised this film the greatest filmed opera ever didn read somewhere either don care for opera don care for wagner don care about anything except their desire appear cultured either representation wagner swan song movie this strikes unmitigated disaster with leaden reading the score matched tricksy lugubrious realisation the text questionable that people with ideas what opera for that matter play especially one shakespeare about should allowed anywhere near theatre film studio syberberg very fashionably but without the smallest justification from wagner text decided that parsifal about bisexual integration that the title character the latter stages transmutes into kind beatnik babe though one who continues sing high tenor few any the actors the film are the singers and get double dose armin jordan the conductor who seen the face but not heard the voice amfortas and also appears monstrously double exposure kind batonzilla conductor who ate monsalvat during the playing the good friday music which the way the transcendant loveliness nature represented scattering shopworn and flaccid crocuses stuck ill laid turf expedient which baffles the theatre sometimes have piece out such imperfections with our thoughts but can think why syberberg couldn splice for parsifal and gurnemanz mountain pasture lush was provided for julie andrews sound music the sound hard endure the high voices and the trumpets particular possessing aural glare that adds another sort fatigue our impatience with the uninspired conducting and paralytic unfolding the ritual someone another review mentioned the bayreuth recording and knappertsbusch though his tempi are often very slow had what jordan altogether lacks sense pulse feeling for the ebb and flow the music and after half century the orchestral sound that set modern pressings still superior this film\n",
        "superbly trashy and wondrously unpretentious exploitation hooray the pre credits opening sequences somewhat give the false impression that dealing with serious and harrowing drama but you need not fear because barely ten minutes later until our necks nonsensical chainsaw battles rough fist fights lurid dialogs and gratuitous nudity and ingrid are two orphaned siblings with unusually close and even slightly perverted relationship can you imagine playfully ripping off the towel that covers your sister naked body and then stare her unshaven genitals for several whole minutes well does that his sister and judging her dubbed laughter she doesn mind all sick dude anyway kids they fled from russia with their parents but nasty soldiers brutally slaughtered mommy and daddy friendly smuggler took custody over them however and even raised and trained and ingrid into expert smugglers when the actual plot lifts off years later they facing their ultimate quest the mythical and incredibly valuable white fire diamond coincidentally found mine very few things life ever made little sense the plot and narrative structure white fire but sure lot fun watch most the time you have clue who beating who for what cause and bet the actors understood even less but whatever the violence magnificently grotesque and every single plot twist pleasingly retarded the script goes totally bonkers beyond repair when suddenly and won reveal for what reason needs replacement for ingrid and fred williamson enters the scene with big cigar his mouth and his sleazy black fingers all over the local prostitutes principal opponent italian chick with big breasts but hideous accent the preposterous but catchy theme song plays least dozen times throughout the film there the obligatory falling love montage and loads other attractions god what brilliant experience the original french title translates itself life survive which uniquely appropriate because makes just much sense the rest the movie none\n",
        "dont know why people think this such bad movie its got pretty good plot some good action and the change location for harry does not hurt either sure some its offensive and gratuitous but this not the only movie like that eastwood good form dirty harry and liked pat hingle this movie the small town cop you liked dirty harry then you should see this one its lot better than the dead pool\n",
        "this movie could have been very good but comes way short cheesy special effects and acting could have looked past that the story wasn lousy there was more background story would have been better the plot centers around evil druid witch who linked this woman who gets migraines the movie drags and and never clearly explains anything just keeps plodding christopher walken has part but completely senseless most the movie this movie had potential but looks like some really bad made for movie would avoid this movie\n",
        "watched this video friend house glad did not waste money buying this one the video cover has scene from the movie capricorn one the movie starts out with several clips rocket blow ups most not related manned flight sibrel smoking gun short video clip the astronauts preparing video broadcast edits his own voice over instead letting listen what the crew had say the video curiously ends with showing the zapruder film his claims about radiation shielding star photography and others lead believe extremely ignorant has some sort grind against nasa the astronauts american general his science bad and this video\n",
        "friend mine bought this film for and even then was grossly overpriced despite featuring big names such adam sandler billy bob thornton and the incredibly talented burt young this film was about funny taking chisel and hammering straight through your earhole uses tired bottom the barrel comedic techniques consistently breaking the fourth wall sandler talks the audience and seemingly pointless montages hot girls adam sandler plays waiter cruise ship who wants make successful comedian order become successful with women when the ship resident comedian the shamelessly named dickie due his unfathomable success with the opposite gender presumed lost sea sandler character shecker gets his big break dickie not dead rather locked the bathroom presumably sea sick perhaps from his mouth just vomited the worst film all time\n",
        "this movie full references like mad max the wild one and many others the ladybug face clear reference tribute peter lorre this movie masterpiece talk much more about the future\n",
        "fitting pipeline... \n",
        "25 Fold CV Score: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.964641955994\n",
        "Retrain on all training data, predicting test labels...\n",
        "\n",
        "[ 0.98821375  0.02077675  0.57377318 ...,  0.38864429  0.96238562\n",
        "  0.69040805]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Wrote results to Bag_of_Words_model.csv"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 102
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "c=16 | 25 Fold CV Score:  0.96409904\n",
      "c=17 | 25 Fold CV Score:  0.96408976\n",
      "c=13 | 25 Fold CV Score:  0.96410064\n",
      "c=09 | 25 Fold CV Score:  0.96406416\n",
      "c=08 | 25 Fold CV Score:  0.96402832\n",
      "c=14 | 25 Fold CV Score:  0.96410448\n",
      "c=14 tf=2 | 25 Fold CV Score:  0.96444656*\n",
      "c=14 tf=2 | 35 Fold CV Score:  0.96461634252\n",
      "c=14 tf=2 | 36 Fold CV Score:  0.964697569423\n",
      "c=14 tf=1 | 25 Fold CV Score:  0.96239056\n",
      "c=12 | 25 Fold CV Score:  0.96409408\n",
      "c=11 | 25 Fold CV Score:  0.96408656\n",
      "c=15 | 25 Fold CV Score:  0.9641014\n",
      "c=14.8 | 25 Fold CV Score:  0.96410384\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "#from KaggleWord2VecUtility import KaggleWord2VecUtility\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "from sklearn.preprocessing import LabelEncoder \n",
      "from sklearn import cross_validation\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import re\n",
      "import nltk\n",
      "\n",
      "from bs4 import BeautifulSoup\n",
      "from nltk.corpus import stopwords\n",
      "\n",
      "class KaggleWord2VecUtility(object):\n",
      "    \"\"\"KaggleWord2VecUtility is a utility class for processing raw HTML text into segments for further learning\"\"\"\n",
      "\n",
      "    @staticmethod\n",
      "    def review_to_wordlist( review, remove_stopwords=False ):\n",
      "        # Function to convert a document to a sequence of words,\n",
      "        # optionally removing stop words.  Returns a list of words.\n",
      "        #\n",
      "        # 1. Remove HTML\n",
      "        review_text = BeautifulSoup(review).get_text()\n",
      "        #\n",
      "        # 2. Remove non-letters\n",
      "        review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n",
      "        \n",
      "        # 2.1 Remove single letters\n",
      "        #review_text = re.sub('/(?<!\\S).(?!\\S)\\s*/', '', review_text);\n",
      "        #\n",
      "        # 3. Convert words to lower case and split them\n",
      "        words = review_text.lower().split()\n",
      "        #\n",
      "        # 4. Optionally remove stop words (false by default)\n",
      "        if remove_stopwords:\n",
      "            stops = set(stopwords.words(\"english\"))\n",
      "            words = [w for w in words if not w in stops]\n",
      "        #\n",
      "        # 5. Return a list of words\n",
      "        return(words)\n",
      "\n",
      "    # Define a function to split a review into parsed sentences\n",
      "    @staticmethod\n",
      "    def review_to_sentences( review, tokenizer, remove_stopwords=False ):\n",
      "        # Function to split a review into parsed sentences. Returns a\n",
      "        # list of sentences, where each sentence is a list of words\n",
      "        #\n",
      "        # 1. Use the NLTK tokenizer to split the paragraph into sentences\n",
      "        raw_sentences = tokenizer.tokenize(review.decode('utf8').strip())\n",
      "        #\n",
      "        # 2. Loop over each sentence\n",
      "        sentences = []\n",
      "        for raw_sentence in raw_sentences:\n",
      "            # If a sentence is empty, skip it\n",
      "            if len(raw_sentence) > 0:\n",
      "                # Otherwise, call review_to_wordlist to get a list of words\n",
      "                sentences.append( KaggleWord2VecUtility.review_to_wordlist( raw_sentence, \\\n",
      "                  remove_stopwords ))\n",
      "        #\n",
      "        # Return the list of sentences (each sentence is a list of words,\n",
      "        # so this returns a list of lists\n",
      "        return sentences\n",
      "    \n",
      "train = pd.read_csv(\"/Users/taposh/workspace/kaggle/bow/labeledTrainData.tsv\", header=0,delimiter=\"\\t\", quoting=3)\n",
      "test = pd.read_csv(\"/Users/taposh/workspace/kaggle/bow/testData.tsv\", header=0, delimiter=\"\\t\",quoting=3)    \n",
      "\n",
      "#train = pd.read_csv(\"/Users/taposh/workspace/kaggle/bow/labeledTrainData.tsv\", header=0, \\\n",
      "#                    delimiter=\"\\t\", quoting=3)\n",
      "#test = pd.read_csv(\"/Users/taposh/workspace/kaggle/bow/testData.tsv\", header=0, delimiter=\"\\t\", \\\n",
      "                   #quoting=3 )\n",
      "y = train[\"sentiment\"]  \n",
      "print(\"Cleaning and parsing movie reviews...\\n\")      \n",
      "traindata = []\n",
      "for i in range( 0, len(train[\"review\"])):\n",
      "    traindata.append(\" \".join(KaggleWord2VecUtility.review_to_wordlist(train[\"review\"][i], False)))\n",
      "testdata = []\n",
      "for i in range(0,len(test[\"review\"])):\n",
      "    testdata.append(\" \".join(KaggleWord2VecUtility.review_to_wordlist(test[\"review\"][i], False)))\n",
      "    #print(testdata)\n",
      "print ('vectorizing... ',) \n",
      "tfv = TfidfVectorizer(min_df=6,  max_features=None, \n",
      "        strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n",
      "        ngram_range=(1, 2), use_idf=1,smooth_idf=1,sublinear_tf=1,\n",
      "        stop_words = 'english')\n",
      "X_all = traindata + testdata\n",
      "lentrain = len(traindata)\n",
      "\n",
      "print (\"fitting pipeline... \",)\n",
      "tfv.fit(X_all)\n",
      "X_all = tfv.transform(X_all)\n",
      "\n",
      "# RF transform 1st column to numbers\n",
      "#X_all[:,0] = LabelEncoder().fit_transform(X_all[:,0])\n",
      "\n",
      "\n",
      "#for Logit\n",
      "X = X_all[:lentrain]\n",
      "X_test = X_all[lentrain:]\n",
      "\n",
      "\n",
      "#model = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None\n",
      "model = LogisticRegression(penalty='l2', dual=True, tol=0.00001,C=14, fit_intercept=True, intercept_scaling=1,class_weight=None, random_state=None)\n",
      "\n",
      "#model = RandomForestRegressor(n_estimators=150, min_samples_split=1)\n",
      "#model.fit(X, y)\n",
      "#print X\n",
      "#print regressor.predict(X)\n",
      "\n",
      "print(\"25 Fold CV Score: \", np.mean(cross_validation.cross_val_score(model, X, y, cv=25, scoring='roc_auc')))\n",
      "\n",
      "print(\"Retrain on all training data, predicting test labels...\\n\")\n",
      "model.fit(X,y)\n",
      "result = model.predict_proba(X_test)[:,1]\n",
      "#result = model.predict(X_test)\n",
      "print(result)\n",
      "output = pd.DataFrame( data={\"id\":test[\"id\"], \"sentiment\":result} )\n",
      "\n",
      "import csv\n",
      "# Use pandas to write the comma-separated output file\n",
      "output.to_csv('/Users/taposh/workspace/kaggle/bow/Bag_of_Words_model_v14_8.csv',quoting=3, escapechar=\",\",index=False,encoding='utf-8')\n",
      "#output.to_csv(\"/Users/taposhdr/workspace/decision_science/kaggle/bow/data/Bag_of_Words_model-1.csv\", index=False, quoting=csv.QUOTE_NONE)\n",
      "print(\"Wrote results to Bag_of_Words_model.csv\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Cleaning and parsing movie reviews...\n",
        "\n",
        "vectorizing... "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "fitting pipeline... "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "25 Fold CV Score: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.96347984\n",
        "Retrain on all training data, predicting test labels...\n",
        "\n",
        "[ 0.99295209  0.01453209  0.50232769 ...,  0.38160522  0.9631343\n",
        "  0.63780148]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Wrote results to Bag_of_Words_model.csv"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 62
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "#from KaggleWord2VecUtility import KaggleWord2VecUtility\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "from sklearn.preprocessing import LabelEncoder \n",
      "from sklearn import cross_validation\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import re\n",
      "import nltk\n",
      "\n",
      "from bs4 import BeautifulSoup\n",
      "from nltk.corpus import stopwords\n",
      "\n",
      "class KaggleWord2VecUtility(object):\n",
      "    \"\"\"KaggleWord2VecUtility is a utility class for processing raw HTML text into segments for further learning\"\"\"\n",
      "\n",
      "    @staticmethod\n",
      "    def review_to_wordlist( review, remove_stopwords=False ):\n",
      "        # Function to convert a document to a sequence of words,\n",
      "        # optionally removing stop words.  Returns a list of words.\n",
      "        #\n",
      "        # 1. Remove HTML\n",
      "        review_text = BeautifulSoup(review).get_text()\n",
      "        #\n",
      "        # 2. Remove non-letters\n",
      "        review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n",
      "        \n",
      "        # 2.1 Remove single letters\n",
      "        #review_text = re.sub('/(?<!\\S).(?!\\S)\\s*/', '', review_text);\n",
      "        #\n",
      "        # 3. Convert words to lower case and split them\n",
      "        words = review_text.lower().split()\n",
      "        #\n",
      "        # 4. Optionally remove stop words (false by default)\n",
      "        if remove_stopwords:\n",
      "            stops = set(stopwords.words(\"english\"))\n",
      "            words = [w for w in words if not w in stops]\n",
      "        #\n",
      "        # 5. Return a list of words\n",
      "        return(words)\n",
      "\n",
      "    # Define a function to split a review into parsed sentences\n",
      "    @staticmethod\n",
      "    def review_to_sentences( review, tokenizer, remove_stopwords=False ):\n",
      "        # Function to split a review into parsed sentences. Returns a\n",
      "        # list of sentences, where each sentence is a list of words\n",
      "        #\n",
      "        # 1. Use the NLTK tokenizer to split the paragraph into sentences\n",
      "        raw_sentences = tokenizer.tokenize(review.decode('utf8').strip())\n",
      "        #\n",
      "        # 2. Loop over each sentence\n",
      "        sentences = []\n",
      "        for raw_sentence in raw_sentences:\n",
      "            # If a sentence is empty, skip it\n",
      "            if len(raw_sentence) > 0:\n",
      "                # Otherwise, call review_to_wordlist to get a list of words\n",
      "                sentences.append( KaggleWord2VecUtility.review_to_wordlist( raw_sentence, \\\n",
      "                  remove_stopwords ))\n",
      "        #\n",
      "        # Return the list of sentences (each sentence is a list of words,\n",
      "        # so this returns a list of lists\n",
      "        return sentences\n",
      "    \n",
      "train = pd.read_csv(\"/Users/taposh/workspace/kaggle/bow/labeledTrainData.tsv\", header=0,delimiter=\"\\t\", quoting=3)\n",
      "test = pd.read_csv(\"/Users/taposh/workspace/kaggle/bow/testData.tsv\", header=0, delimiter=\"\\t\",quoting=3)    \n",
      "\n",
      "#train = pd.read_csv(\"/Users/taposh/workspace/kaggle/bow/labeledTrainData.tsv\", header=0, \\\n",
      "#                    delimiter=\"\\t\", quoting=3)\n",
      "#test = pd.read_csv(\"/Users/taposh/workspace/kaggle/bow/testData.tsv\", header=0, delimiter=\"\\t\", \\\n",
      "                   #quoting=3 )\n",
      "y = train[\"sentiment\"]  \n",
      "print(\"Cleaning and parsing movie reviews...\\n\")      \n",
      "traindata = []\n",
      "for i in range( 0, len(train[\"review\"])):\n",
      "    traindata.append(\" \".join(KaggleWord2VecUtility.review_to_wordlist(train[\"review\"][i], False)))\n",
      "testdata = []\n",
      "for i in range(0,len(test[\"review\"])):\n",
      "    testdata.append(\" \".join(KaggleWord2VecUtility.review_to_wordlist(test[\"review\"][i], False)))\n",
      "    #print(testdata)\n",
      "print ('vectorizing... ',) \n",
      "tfv = TfidfVectorizer(min_df=4,  max_features=None, \n",
      "        strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n",
      "        ngram_range=(1, 2), use_idf=1,smooth_idf=1,sublinear_tf=1,\n",
      "        stop_words = 'english')\n",
      "X_all = traindata + testdata\n",
      "lentrain = len(traindata)\n",
      "\n",
      "print (\"fitting pipeline... \",)\n",
      "tfv.fit(X_all)\n",
      "X_all = tfv.transform(X_all)\n",
      "\n",
      "# RF transform 1st column to numbers\n",
      "#X_all[:,0] = LabelEncoder().fit_transform(X_all[:,0])\n",
      "\n",
      "\n",
      "#for Logit\n",
      "X = X_all[:lentrain]\n",
      "X_test = X_all[lentrain:]\n",
      "\n",
      "\n",
      "#model = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None\n",
      "model = LogisticRegression(penalty='l2', dual=True, tol=0.00001,C=11, fit_intercept=True, intercept_scaling=1,class_weight=None, random_state=None)\n",
      "\n",
      "#model = RandomForestRegressor(n_estimators=150, min_samples_split=1)\n",
      "#model.fit(X, y)\n",
      "#print X\n",
      "#print regressor.predict(X)\n",
      "\n",
      "print(\"25 Fold CV Score: \", np.mean(cross_validation.cross_val_score(model, X, y, cv=25, scoring='roc_auc')))\n",
      "\n",
      "print(\"Retrain on all training data, predicting test labels...\\n\")\n",
      "model.fit(X,y)\n",
      "result = model.predict_proba(X_test)[:,1]\n",
      "#result = model.predict(X_test)\n",
      "print(result)\n",
      "output = pd.DataFrame( data={\"id\":test[\"id\"], \"sentiment\":result} )\n",
      "\n",
      "import csv\n",
      "# Use pandas to write the comma-separated output file\n",
      "output.to_csv('/Users/taposh/workspace/kaggle/bow/Bag_of_Words_model_v11.csv',quoting=3, escapechar=\",\",index=False,encoding='utf-8')\n",
      "#output.to_csv(\"/Users/taposhdr/workspace/decision_science/kaggle/bow/data/Bag_of_Words_model-1.csv\", index=False, quoting=csv.QUOTE_NONE)\n",
      "print(\"Wrote results to Bag_of_Words_model.csv\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Cleaning and parsing movie reviews...\n",
        "\n",
        "vectorizing... "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "fitting pipeline... "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "25 Fold CV Score: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.96408656\n",
        "Retrain on all training data, predicting test labels...\n",
        "\n",
        "[ 0.99110772  0.01987447  0.5607115  ...,  0.38636618  0.96060281\n",
        "  0.6428434 ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Wrote results to Bag_of_Words_model.csv"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 56
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}