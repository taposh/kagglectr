{
    "contents" : "#--------------------------------------------------------\n#  Non-Grid based models for kaggle-bike-sharing\n#  Taposh Roy\n#  @taposh_dr\n#--------------------------------------------------------\n\n\n#For counts\ntrain_factor <- cbind(countresult,bike)\ncolnames(train_factor)[1] <- \"count\"\ncolnames(train_factor)\n\n#For causal\ntrain_factor_causal <- cbind(causal,bike)\ncolnames(train_factor_causal)[1] <- \"causal\"\ncolnames(train_factor_causal)\n\n#For registered\ntrain_factor_registered <- cbind(registered,bike)\ncolnames(train_factor_registered)[1] <- \"registered\"\ncolnames(train_factor_registered)\n\n#Columns Created\ncolnames(bike)\ncolnames(test)\n#write.table(train_factor,file=\"train_factors_h2o.csv\",row.names=FALSE,quote=FALSE,sep=\",\",col.names=TRUE)\n#write.table(test,file=\"test_factors_h2o.csv\",row.names=FALSE,quote=FALSE,sep=\",\",col.names=TRUE)\n\n\n###################\n###Result Analysis\n##################\nresult.train<-c()\nresult.train <- data.frame(countresult)\nhead(result.train)\ncolnames(result.train) <- c(\"actual\")\nresult.stat<-c()\nresult.test<-c()\n\n\n#forumla_count <-count ~ season + holiday + workingday + weather + temp + atemp + humidity + windspeed + hour + month + dayof + temp2 + atemp2 + humid2 + windspeed2\nforumla_count <-count ~.\n#forumla_causal <-causal ~ season + holiday + workingday + weather + temp + atemp + humidity + windspeed + hour + month + dayof + temp2 + atemp2 + humid2 + windspeed2\nforumla_causal <-causal ~.\n#forumla_registered <-registered ~ season + holiday + workingday + weather + temp + atemp + humidity + windspeed + hour + month + dayof + temp2 + atemp2 + humid2 + windspeed2\nforumla_registered <-registered ~.\n\n#times<-paste(test[,\"datetime\"])\n##################################\n# Method 1 : randomForest\n##################################\n\n#####RANDOM FOREST STARTS HERE#########\n#variables\nmyNtree = 600\nmyMtry = 15\nmyImportance = TRUE\n#set the random seed\nset.seed(415)\n\n#Counts\ncountFit <- randomForest(forumla_count, data=train_factor, ntree=myNtree, mtry=myMtry, importance=myImportance,na.action = na.omit)\ntrain_count_predict_1 <- predict(countFit,bike)\ntest_count_predict_1 <- predict(countFit,test)\ncompare.rf.bike.count <- cbind(train_factor[,1],train_count_predict_1)\nhead(compare.rf.bike.count,10)\n\nauc_Counts <-auc(train_factor[,1],train_count_predict_1)\nrmsle_Counts_rf<-rmsle(train_factor[,1],train_count_predict_1)\nrmsle_Counts_rf\n# myroc <- roc(train_factor[,1],train_count_predict_1)\n# myci <- ci(train_factor[,1],train_count_predict_1)\n# plot(myroc)\n\n\n\n####create output file from dataset test with predictions\n# test_dt<-read.csv(\"test.csv\")\n# test_dt<-(as.data.frame(test_dt))\n# submit <- data.frame (datetime = test_dt$datetime, count =test_count_predict_1 )\n# head(submit)\n# curtime <- Sys.time()\n# timestamp <-  strftime(curtime,\"%Y-%m-%d-%H-%M-%S\")\n# timestamp2 <-paste(\"Submission_rf_method1_count\",timestamp,\".csv\", sep=\"_\")\n# write.table(submit,file=timestamp2,row.names=FALSE,quote=FALSE,sep=\",\",col.names=TRUE)\n\n\n#fit and predict casual\ncasualFit <- randomForest(forumla_causal, data=train_factor_causal, ntree=myNtree, mtry=myMtry, importance=myImportance,na.action = na.omit)\ntrain_causal_predict <- predict(casualFit,bike)\ntest_causal_predict <- predict(casualFit, test)\n\n\n#fit and predict registered\nregisteredFit <- randomForest(forumla_registered, data=train_factor_registered, ntree=myNtree, mtry=myMtry, importance=myImportance,na.action = na.omit)\ntrain_registered_predict <- predict(registeredFit, bike)\ntest_registered_predict <- predict(registeredFit, test)\n#add both columns into final count, round to whole number\n\n#### RESULT ##############\nresult.train <- cbind(result.train,rf=train_count_predict_1)\nresult.test <- cbind(result.test,rf=test_count_predict_1)\n\n# head(test_causal_predict)\n# head(test_registered_predict)\n# \n# test_count_predict <- cbind(test_causal_predict+test_registered_predict)\n# train_count_predict <- cbind(train_causal_predict+train_registered_predict)\n# \n# compare.rf.bike <- cbind(train_factor[,1],train_count_predict)\n# head(compare.rf.bike,10)\n# \n# auc_Counts <-auc(train_factor[,1],train_count_predict)\n# rmsle_Counts<-rmsle(train_factor[,1],train_count_predict)\n# rmsle_Counts\n# myroc3 <- roc(train_factor[,1],train_count_predict)\n# myci2 <- ci(train_factor[,1],train_count_predict)\n# plot(myroc3)\n\n\n\n# test_result <- cbind(test_causal_predict+test_registered_predict)\n# head(test_result)\n# #testplot\n# #plot(test_result)\n# #plot(test_result)\n# \n# \n# test_dt<-read.csv(\"test.csv\")\n# test_dt<-(as.data.frame(test_dt))\n# ####create output file from dataset test with predictions\n# submit <- data.frame (datetime = test_dt$datetime, count =test_result )\n# head(submit)\n# curtime <- Sys.time()\n# timestamp <-  strftime(curtime,\"%Y-%m-%d-%H-%M-%S\")\n# timestamp2 <-paste(\"Submission_rf_method1\",timestamp,\".csv\", sep=\"_\")\n# write.table(submit,file=timestamp2,row.names=FALSE,quote=FALSE,sep=\",\",col.names=TRUE)\n\n\n##################################\n# Method 2 : randomForest\n##################################\n\nrequire(randomForest) \nset.seed(17)\nmdl_rf <- randomForest(count ~., data=train_factor, mtry = 16,ntree=600, importance = TRUE,na.action = na.omit)  \nvarImpPlot(mdl_rf)\n\n#training data \nprd.rf <- predict(mdl_rf, data=bike,type='response')\nprd.rf <- as.data.frame(prd.rf)\n# compare.rf.bike <- cbind(train_factor[,1],prd.rf)\n# head(compare.rf.bike,10)\n# \n# auc_Counts <-auc(train_factor[,1],prd.rf)\n# rmsle_Counts<-rmsle(train_factor[,1],prd.rf)\n# rmsle_Counts\n# myroc21 <- roc(train_factor[,1],prd.rf)\n# myci2 <- ci(train_factor[,1],prd.rf)\n# plot(myroc21)\n\n#test data\nprd.test.rf.bike <- predict(mdl_rf, newdata=as.data.frame(test),type='response')  \nbike.test.rf <- as.data.frame(prd.test.rf.bike)\n\n# head(bike.test.rf)\n# nrow(prd.rf)\n# head(prd.rf)\n\nerror<-sqrt((sum((train_factor[,1]-prd.rf)^2))/nrow(bike))\nerror\n\n######################\n\n# #Count Predictions\n# datetimes_test = as.data.frame(test_dt[,\"datetime\"])\n# colnames(datetimes_test) <- c(\"datetime\")\n# \n# nrow(datetimes_test)\n# nrow(prd.test.rf.bike)\n# \n# Predictions<-cbind(datetimes_test,prd.test.rf.bike)\n# colnames(Predictions)<-c(\"datetime\",\"count\")\n# head(Predictions)\n\n#### RESULT ##############\nresult.train <- cbind(result.train,rf2=prd.rf)\nresult.test <- cbind(result.test,prd.rf=prd.test.rf.bike)\n\n# head(result.train)\n# ########################################################\n# ## Output\n# ########################################################\n# \n# curtime <- Sys.time()\n# timestamp <-  strftime(curtime,\"%Y-%m-%d-%H-%M-%S\")\n# timestamp2 <-paste(\"Submission_rf\",timestamp,\".csv\", sep=\"_\")\n# write.table(Predictions,file=timestamp2,row.names=FALSE,quote=FALSE,sep=\",\",col.names=TRUE)\n# x<-paste(timestamp2,\"AUC\",auc_Counts,\"Logloss\",rmsle_Counts,collapse=\"  \")\n# print(x)\n# write(x, file = \"Results_compare.txt\",append = TRUE, sep = \" \")\n# \n\n\n########################################################\n## Forumula\n########################################################\n#All factors determined\n\n#forumla <- toString(paste(\"count ~\",paste(unique(colnames(as.data.frame(bike))), collapse=\" + \")))\n# forumla <-count ~ season + holiday + workingday + weather + temp + atemp + humidity + windspeed + hour + month + dayof + temp2 + atemp2 + humid2 + windspeed2\n\n#forumla <- count ~ season + holiday + workingday + weather + temp + atemp + humidity + windspeed + hour + month + dayof + temp2 + atemp2 + humid2 + windspeed2 + temp3 + atemp3 + humid3 + windspeed3 + logtemp + logatemp + sinhumid + coshumid + sinhumid2 + coshumid2 + sinhumid3 + coshumid3 + sinwind + coswind + sinwind2 + coswind2 + sinwind3 + coswind3 + btsaweather + btsaweathertemp + Number\n\n# t1 + t3 + t5 + t6 + t8 + t9 + t11 + t13 + t14 + t15 + t16 + tt +\n\n###################################\n# Algorithms\n##################################\n\n#head(bike)\n\n\n##################################\n# Method 1: GBM\n##################################\nlibrary(gbm)\n#Gradient Boosted Method\nmodelgbm<-gbm(count ~., data=as.data.frame(train_factor),distribution='poisson',n.trees =1500,train.fraction = 1.0,cv.folds=25,shrinkage = 0.001,interaction.depth=5)\n#Build generalized boosted model (gradient boosted macine).\n#modelgbm\n# check performance using an out-of-bag estimator\n# OOB underestimates the optimal number of iterations\nbest.iter <- gbm.perf(modelgbm,plot.it = TRUE,overlay=TRUE,method=\"OOB\",oobag.curve=TRUE)\nprint(best.iter)\n\n#show(fit.gbm)\n# gbmVarImp<-varImp(best.iter)  \n# plot(gbmVarImp)\n\n# plot the performance # plot variable influence\n#summary(modelgbm,n.trees=800)         # based on the first tree\nsummary(modelgbm,n.trees=best.iter) # based on the estimated best number of trees\n\n# compactly print the first and last trees for curiosity\n#print(pretty.gbm.tree(modelgbm,1))\n#print(pretty.gbm.tree(modelgbm,gbm$n.trees))\n\n\n#bst <- gbm.perf(modelgbm,method=\"OOB\")                                                #Show plot of performance and store best\n\ncolnames(bike)\n#colnames(train_factor)\n\npredict.train.gbm <- predict(modelgbm, data=as.data.frame(bike), type=\"response\")\n\n# #comparegbm <- cbind(countresult,predict.train.gbm)\n# head(comparegbm)\n# #auc_gbm<-auc(countresult,predict.train.gbm)\n# rmsle_gbm <-rmsle(countresult,predict.train.gbm)\n# myrocgbm <- roc(countresult,predict.train.gbm)\n# plot(myrocgbm)\n\n#Get prediction.\npredict.test.gbm <- predict(modelgbm, data=test, type=\"response\")\n#head(predict.test.gbm)\n\n#### RESULT ##############\nresult.train <- cbind(result.train,gbm=predict.train.gbm)\nresult.test <- cbind(result.test,gbm=predict.test.gbm)\n\n# curtime <- Sys.time()\n# timestampgbm <-  strftime(curtime,\"%Y-%m-%d-%H-%M-%S\")\n# timestampgbm1 <-paste(\"Submission_gbm\",timestampgbm,\".csv\", sep=\"_\")\n# write.table(predict.test.gbm ,file=timestampgbm1,row.names=FALSE,quote=FALSE,sep=\",\",col.names=TRUE)\n# \n# xgbm<-paste(timestampgbm1,\"AUC\",auc_gbm,\"Logloss\",rmsle_gbm,collapse=\"  \")\n# print(xgbm)\n# write(xgbm, file = \"Results_compare.txt\",append = TRUE, sep = \" \")\n\n\n\n##################################\n# Method 3: Neural Net1\n##################################\nrequire(neuralnet)\nmdl_nnet <- nnet( count~., data=train_factor, size=10,decay=5e-4,rang = 0.1, maxit=1000)                      #Build neural net.\nmdl_nnet\n\ntrain.prob.nnet<- compute(mdl_nnet,bike)\n# compare.bike <- cbind(train_factor[1],train.prob.nnet)\n# head(compare.bike)\n# \n\n\ntest.prd.ann <- predict(mdl_nnet, newdata=test)  #Get prediction.#Clean up.\n# compare.nn.blood <- cbind(train_factor[1],train.prob.nnet)\n# head(compare.nn.blood)\n# auc_Counts3 <-auc(train_factor[1],train.prob.nnet)\n# rmsle_Counts3<-rmsle(train_factor[1],train.prob.nnet)\n# rmsle_Counts3\n# myroc3 <- roc(train_factor[1],train.prob.nnet)\n# myci3 <- ci(train_factor[1],train.prob.nnet)\n# plot(myroc3)\n# \n# head(test.prd.ann) \n\n#### RESULT ##############\nresult.train <- cbind(result.train,neuralnet=train.prob.nnet)\nresult.test <- cbind(result.test,neuralnet=test.prd.ann)\n\n# #Count Predictions\n# nnPredictions<-cbind(test[,\"id\"],test.prd.ann)\n# colnames(nnPredictions)<-c(\"id\",\"Made Donation in March 2007\")\n# head(nnPredictions)\n# \n# ########################################################\n# ## Output\n# ########################################################\n# \n# curtime <- Sys.time()\n# timestamp <-  strftime(curtime,\"%Y-%m-%d-%H-%M-%S\")\n# timestamp1 <-paste(\"Submission_combo_nn\",timestamp,\".csv\", sep=\"_\")\n# timestamp2 <-paste(\"Submission_nn\",timestamp,\".csv\", sep=\"_\")\n# \n# write.table(Predictions_comb,file=timestamp1,row.names=FALSE,quote=FALSE,sep=\",\",col.names=TRUE)\n# write.table(Predictions,file=timestamp2,row.names=FALSE,quote=FALSE,sep=\",\",col.names=TRUE)\n# \n# x<-paste(timestamp2,\"AUC\",auc_Counts,\"Logloss\",rmsle_Counts,collapse=\"  \")\n# print(x)\n# write(x, file = \"Results_compare.txt\",append = TRUE, sep = \" \")\n\n##\n## Output\n##\n\n# curtime <- Sys.time()\n# timestampnn <-  strftime(curtime,\"%Y-%m-%d-%H-%M-%S\")\n# timestampnn1 <-paste(\"Submission_nn\",timestamp,\".csv\", sep=\"_\")\n# \n# write.table(nnPredictions,file=timestampnn1,row.names=FALSE,quote=FALSE,sep=\",\",col.names=TRUE)\n# \n# x<-paste(timestampnn1,\"AUC\",auc_nn,\"Logloss\",rmsle_nn,collapse=\"  \")\n# print(x)\n# write(x, file = \"Results_compare.txt\",append = TRUE, sep = \" \")\n\n##################################\n# Method  : CTREE\n##################################\n# source(\"ctree.R\")\n# #head(Predictionsct)\n# \n\n\n\nbestresult <- read.csv(\"/Users/taposh/Desktop/deduced.csv\")\nhead(bestresult)\n\nresult.test <- cbind(result.test,bestresult)\nhead(result.train,10)\nhead(result.test,10)\n\nresult.train1 <- data.frame(result.train)\nresult.test1<- data.frame(result.test)\n\ncolnames(result.test) <- c(rf,prd.rf,gbm)\n\n#result.test <- result.test[-4]\n\ncolnames(result.test)\n\n##########################################################\n#Final GLM\n##########################################################\nset.seed(123)\nfitControl <- trainControl(method = 'cv', number = 10, summaryFunction=my2metric)\nGrid <- expand.grid( n.trees = seq(100,3000,100), interaction.depth = c(30), shrinkage = c(0.075))\nformula <- actual ~.\n#fit.gbm<-gbm(count ~., data=as.data.frame(train_factor),verbose=FALSE,distribution='poisson')\n\nfit.gbm <- train(actual ~., data=result.train, method = 'gbm', trControl=fitControl, verbose=FALSE,tuneGrid=Grid,metric='RMSLE',maximize=FALSE,distribution='poisson')\n\n\nplot(fit.gbm)\ngbmVarImp<-varImp(fit.gbm)  \nplot(gbmVarImp)\n\n\n\nwrite.submission(fit.gbm, 'submission_gbm_layer2.csv',result.test,test_dt)\nsave(fit.gbm,file='fit_gbm_layer2.RData')\n\n  \n#fit <- glm(actual ~., result.train, family='poisson')\n#summary(fit)\n\n\n########################################################\n## Output\n########################################################\n\n# curtime <- Sys.time()\n# timestamp <-  strftime(curtime,\"%Y-%m-%d-%H-%M-%S\")\n# timestamp1 <-paste(\"Submission_combo_ctree\",timestamp,\".csv\", sep=\"_\")\n# timestamp2 <-paste(\"Submission_ctree\",timestamp,\".csv\", sep=\"_\")\n# \n# write.table(Predictions_comb,file=timestamp1,row.names=FALSE,quote=FALSE,sep=\",\",col.names=TRUE)\n# write.table(Predictions,file=timestamp2,row.names=FALSE,quote=FALSE,sep=\",\",col.names=TRUE)\n# \n# x<-paste(timestamp2,\"AUC\",auc_Counts,\"Logloss\",rmsle_Counts,collapse=\"  \")\n# print(x)\n# write(x, file = \"Results_compare.txt\",append = TRUE, sep = \" \")\n# \n# \n",
    "created" : 1422206519047.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1037975677",
    "id" : "DFB8D354",
    "lastKnownWriteTime" : 1422342358,
    "path" : "~/workspace/kaggle/bikeshare/models_nongrid_2layer.R",
    "project_path" : "models_nongrid_2layer.R",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "source_on_save" : false,
    "type" : "r_source"
}